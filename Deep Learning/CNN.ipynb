{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf0eb31-0704-4c87-88de-a653e606b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71cf2f2b-a363-4c07-8e0d-b833571789d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7c04ac1-0762-4aee-8efe-ab74f546f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d34018ab-b938-46e7-b92d-aeb519181843",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Conv2D(32,(3,3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "cnn.add(Conv2D(16,(3,3), activation=\"relu\"))\n",
    "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
    "cnn.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61d6037-c4f5-450f-9cb7-26eaf6a4d9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Dense(64,activation=\"relu\"))\n",
    "cnn.add(Dense(32,activation=\"relu\"))\n",
    "cnn.add(Dense(16,activation=\"relu\"))\n",
    "cnn.add(Dense(8,activation=\"relu\"))\n",
    "cnn.add(Dense(4,activation=\"relu\"))\n",
    "cnn.add(Dense(1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5af0d360-504b-498c-a6db-1a22f98e5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(loss = \"binary_crossentropy\",optimizer = \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00b5559b-1e49-4eef-bd9a-b5d1a9e3bbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://faroit.com/keras-docs/1.2.0/preprocessing/image/ -code from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab7c71f7-38a9-468f-9332-8c66eb66fc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24998 images belonging to 2 classes.\n",
      "Found 204 images belonging to 2 classes.\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 134ms/step - loss: 0.7148 - val_loss: 0.6871\n",
      "Epoch 2/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 133ms/step - loss: 0.6904 - val_loss: 0.6750\n",
      "Epoch 3/5\n",
      "\u001b[1m173/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - loss: 0.6615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/PIL/TiffImagePlugin.py:890: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 136ms/step - loss: 0.6604 - val_loss: 0.5978\n",
      "Epoch 4/5\n",
      "\u001b[1m182/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 124ms/step - loss: 0.6102"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 23:09:25.346205: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/opt/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 114ms/step - loss: 0.6094 - val_loss: 0.5159\n",
      "Epoch 5/5\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 140ms/step - loss: 0.5819 - val_loss: 0.4840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x168ebf980>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/Users/shubhamyadav/Downloads/PetImages/Train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '/Users/shubhamyadav/Downloads/PetImages/Test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "cnn.fit(train_generator, steps_per_epoch=200, epochs=5, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30bd6655-9872-4e9c-b112-bb38810bd6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "373e6c1d-e1d7-4aee-a06b-869a2fd0b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('/Users/shubhamyadav/Downloads/PetImages/Test/Cat Test/2.jpg',target_size=(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e94df16-8253-426f-bb72-463cee5cc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e9360eaa-a67d-47c9-993b-617047254fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.expand_dims(img,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfdbd55d-4235-4901-a4d4-9aae942f2548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07841087-9468-49b8-9fa2-3e3148bbf41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
